#
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

spark.core.connection.ack.wait.timeout                   300
spark.driver.extraJavaOptions                            -XX:+UseG1GC -XX:-UseBiasedLocking -XX:InitiatingHeapOccupancyPercent=25 -XX:ParallelGCThreads=4 -XX:+UseStringDeduplication -Dsun.net.inetaddr.ttl=300
spark.driver.maxResultSize                               2g
spark.dynamicAllocation.enabled                          true
spark.dynamicAllocation.executorIdleTimeout              10
spark.dynamicAllocation.initialExecutors                 3
spark.dynamicAllocation.maxExecutors                     500
spark.dynamicAllocation.minExecutors                     3
spark.dynamicAllocation.schedulerBacklogTimeout          5
spark.dynamicAllocation.sustainedSchedulerBacklogTimeout 5
spark.dynamicAllocation.cachedExecutorIdleTimeout        900
spark.eventLog.enabled                                   true
spark.eventLog.overwrite                                 true
spark.eventLog.dir                                       hdfs:///spark-logs
spark.executor.cores                                     1
spark.executor.extraJavaOptions                          -XX:+UseG1GC -XX:-UseBiasedLocking -XX:InitiatingHeapOccupancyPercent=25 -XX:ParallelGCThreads=4 -Dsun.net.inetaddr.ttl=300
spark.executor.memory                                    6144m
spark.hadoop.hive.exec.dynamic.partition.mode            nonstrict
spark.hadoop.franklin.batch.size                         1000
spark.hadoop.mapreduce.input.fileinputformat.list-status.num-threads 10
spark.hadoop.mapreduce.input.fileinputformat.split.minsize 256000000
spark.hadoop.mapreduce.input.fileinputformat.split.maxsize 512000000
spark.hadoop.netflix.metacat.host                        http://metacat.dynprod.netflix.net:7001
spark.hadoop.spark.sql.hive.env                          prod
spark.hadoop.parquet.filter.dictionary.enabled           true
spark.hadoop.parquet.memory.min.chunk.size               16777216
spark.hadoop.spark.sql.batch.s3committer.enabled         true
spark.hadoop.spark.sql.s3committer.enabled               true
spark.hadoop.spark.s3committer.enabled                   true
spark.hadoop.hive.exec.compress.output                   true
spark.io.compression.codec                               lz4
spark.kryo.registrationRequired                          false
spark.kryoserializer.buffer.max                          256m
spark.master                                             yarn
spark.reducer.maxReqsInFlight                            10
spark.rdd.compress                                       true
spark.scheduler.executorTaskBlacklistTime                5000
spark.serializer                                         org.apache.spark.serializer.KryoSerializer
spark.shared.archive.path                                hdfs:///spark-shared
spark.shuffle.service.enabled                            true
spark.shuffle.spill                                      true
spark.shuffle.io.maxRetries                              2
spark.shuffle.io.retryWait                               2s
spark.shuffle.io.serverThreads                           2
spark.speculation                                        true
spark.speculation.interval                               15000ms
spark.block.failures.beforeLocationRefresh               2
spark.shuffle.mapOutput.minSizeForBroadcast              65536
spark.sql.adaptive.enabled                               true
spark.sql.autoBroadcastJoinThreshold                     100000000
spark.sql.broadcastTimeout                               -1
spark.sql.catalogImplementation                          hive
spark.sql.franklin.connection.timeout                    1800000
spark.sql.hive.convertMetastoreParquet                   true
spark.sql.hive.metastorePartitionPruning                 true
spark.sql.hive.verifyPartitionPath                       false
spark.sql.insertSafeCasts                                true
spark.sql.parquet.compression.codec                      gzip
spark.sql.shuffle.partitions                             500
spark.sql.sources.parallelPartitionDiscovery.threshold   10000
spark.ui.port                                            0
spark.ui.showConsoleProgress                             true
spark.yarn.am.waitTime                                   10000
spark.yarn.am.force.shutdown                             true
spark.yarn.executor.memoryOverhead                       1024
spark.yarn.maxAppAttempts                                1
spark.yarn.submit.file.replication                       10
spark.executorEnv.JAVA_HOME                              /apps/bdp-java/java-8-oracle
spark.yarn.appMasterEnv.JAVA_HOME                        /apps/bdp-java/java-8-oracle
spark.history.fs.cleaner.enabled                         true
spark.scheduler.listenerbus.eventqueue.size              50000
